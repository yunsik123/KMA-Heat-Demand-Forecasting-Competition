{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import holidays\n",
    "from scipy.fftpack import fft#푸리에 변환을 위한 코드입니다.\n",
    "from scipy.stats import boxcox#박스콕스 변환을 위한 코드임\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# ===== LightGBM 머신러닝 파이프라인 =====\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import Ridge\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#기타\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   🏢 브랜치 A SVR 보간 중... ✅\n",
      "   🏢 브랜치 B SVR 보간 중... ✅\n",
      "   🏢 브랜치 C SVR 보간 중... ✅\n",
      "   🏢 브랜치 D SVR 보간 중... ✅\n",
      "   🏢 브랜치 E SVR 보간 중... ✅\n",
      "   🏢 브랜치 F SVR 보간 중... ✅\n",
      "   🏢 브랜치 G SVR 보간 중... ✅\n",
      "   🏢 브랜치 H SVR 보간 중... ✅\n",
      "   🏢 브랜치 I SVR 보간 중... ✅\n",
      "   🏢 브랜치 J SVR 보간 중... ✅\n",
      "   🏢 브랜치 K SVR 보간 중... ✅\n",
      "   🏢 브랜치 L SVR 보간 중... ✅\n",
      "   🏢 브랜치 M SVR 보간 중... ✅\n",
      "   🏢 브랜치 N SVR 보간 중... ✅\n",
      "   🏢 브랜치 O SVR 보간 중... ✅\n",
      "   🏢 브랜치 P SVR 보간 중... ✅\n",
      "   🏢 브랜치 Q SVR 보간 중... ✅\n",
      "   🏢 브랜치 R SVR 보간 중... ✅\n",
      "   🏢 브랜치 S SVR 보간 중... ✅\n",
      "🎉 SVR 보간 완료 (조건 없이 전부 시도)\n",
      "🚀 STL 시계열 분해 시작...\n",
      "🔄 STL 시계열 분해 특성 생성 중... (대상: ['ta', 'ws'])\n",
      "============================================================\n",
      "⚠️ heat_demand는 테스트 데이터에 없으므로 제외됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "브랜치별 STL 분해: 100%|██████████| 19/19 [02:41<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ STL 시계열 분해 완료!\n",
      "📊 생성된 시계열 특성: 12개\n",
      "📋 특성 목록: ['ta_stl_trend', 'ta_stl_seasonal', 'ta_stl_resid', 'ta_detrend', 'ta_seasonal_strength', 'ta_seasonal_volatility', 'ws_stl_trend', 'ws_stl_seasonal', 'ws_stl_resid', 'ws_detrend']...\n",
      "   🏢 브랜치 A SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 B SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 C SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 D SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 E SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 F SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 G SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 H SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 I SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 J SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 K SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 L SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 M SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 N SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 O SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 P SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 Q SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 R SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "   🏢 브랜치 S SVR 보간 중... \n",
      "   ⚠️ heat_demand SVR 실패 → 선형 보간 대체\n",
      "✅\n",
      "🎉 SVR 보간 완료 (조건 없이 전부 시도)\n",
      "🚀 STL 시계열 분해 시작...\n",
      "🔄 STL 시계열 분해 특성 생성 중... (대상: ['ta', 'ws'])\n",
      "============================================================\n",
      "⚠️ heat_demand는 테스트 데이터에 없으므로 제외됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "브랜치별 STL 분해: 100%|██████████| 19/19 [00:52<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ STL 시계열 분해 완료!\n",
      "📊 생성된 시계열 특성: 12개\n",
      "📋 특성 목록: ['ta_stl_trend', 'ta_stl_seasonal', 'ta_stl_resid', 'ta_detrend', 'ta_seasonal_strength', 'ta_seasonal_volatility', 'ws_stl_trend', 'ws_stl_seasonal', 'ws_stl_resid', 'ws_detrend']...\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train_heat.csv\")\n",
    "df_test = pd.read_csv(\"test_heat.csv\")\n",
    "#열이름빼기\n",
    "df_train.columns = df_train.columns.str.replace('train_heat.', '', regex=False)\n",
    "#Unnamed:0제거\n",
    "df_train = df_train.drop(columns=[\"Unnamed: 0\"])\n",
    "#test데이터 열이름 바꾸기\n",
    "df_test.columns = [\n",
    "    \"tm\", \"branch_id\", \"ta\", \"wd\", \"ws\",\n",
    "    \"rn_day\", \"rn_hr1\", \"hm\", \"si\", \"ta_chi\",\"heat_demand\"]\n",
    "\n",
    "\n",
    "def create_time_series_features(df, target_cols=['ta', 'ws'], freq_hours=23):  # 24→23, hm→ws\n",
    "    \"\"\"시계열 분해를 통한 특성 생성 (STL 분해만 사용)\"\"\"\n",
    "    print(f\"🔄 STL 시계열 분해 특성 생성 중... (대상: {target_cols})\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"⚠️ heat_demand는 테스트 데이터에 없으므로 제외됩니다.\")\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 브랜치별로 시계열 분해 수행\n",
    "    for branch in tqdm(sorted(df['branch_id'].unique()), desc=\"브랜치별 STL 분해\"):\n",
    "        branch_mask = df_features['branch_id'] == branch\n",
    "        branch_data = df_features[branch_mask].copy().sort_values('tm')\n",
    "        \n",
    "        if len(branch_data) < freq_hours * 7:  # 최소 7일 데이터 필요\n",
    "            print(f\"   ⚠️ 브랜치 {branch}: 데이터 부족 ({len(branch_data)}개) - 건너뜀\")\n",
    "            continue\n",
    "        \n",
    "        # 각 대상 변수별로 STL 분해 수행\n",
    "        for col in target_cols:\n",
    "            if col not in branch_data.columns:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # 결측치 처리\n",
    "                col_data = branch_data[col].interpolate().fillna(method='bfill').fillna(method='ffill')\n",
    "                \n",
    "                # STL 분해 (24시간 주기)\n",
    "                try:\n",
    "                    # 시간 인덱스 설정\n",
    "                    ts_data = col_data.copy()\n",
    "                    ts_data.index = pd.to_datetime(branch_data['tm'])\n",
    "                    \n",
    "                    # STL 분해\n",
    "                    stl = STL(ts_data, seasonal=freq_hours, robust=True)\n",
    "                    stl_result = stl.fit()\n",
    "                    \n",
    "                    # STL 결과 저장\n",
    "                    indices = branch_data.index\n",
    "                    df_features.loc[indices, f'{col}_stl_trend'] = stl_result.trend.values\n",
    "                    df_features.loc[indices, f'{col}_stl_seasonal'] = stl_result.seasonal.values\n",
    "                    df_features.loc[indices, f'{col}_stl_resid'] = stl_result.resid.values\n",
    "                    \n",
    "                    # 추가 파생 변수\n",
    "                    df_features.loc[indices, f'{col}_detrend'] = col_data.values - stl_result.trend.values\n",
    "                    df_features.loc[indices, f'{col}_seasonal_strength'] = np.abs(stl_result.seasonal.values)\n",
    "                    \n",
    "                    # 계절성 변동 지표\n",
    "                    seasonal_std = np.std(stl_result.seasonal.values)\n",
    "                    df_features.loc[indices, f'{col}_seasonal_volatility'] = seasonal_std\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      ⚠️ STL 분해 실패 ({col}): {str(e)[:50]}\")\n",
    "                    continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ 브랜치 {branch} {col} 분해 실패: {str(e)[:50]}\")\n",
    "                continue\n",
    "    \n",
    "    # 생성된 시계열 특성 목록\n",
    "    time_series_features = [col for col in df_features.columns \n",
    "                           if any(pattern in col for pattern in ['_stl_', '_detrend', '_seasonal_strength', '_seasonal_volatility'])]\n",
    "    \n",
    "    print(f\"\\n✅ STL 시계열 분해 완료!\")\n",
    "    print(f\"📊 생성된 시계열 특성: {len(time_series_features)}개\")\n",
    "    print(f\"📋 특성 목록: {time_series_features[:10]}{'...' if len(time_series_features) > 10 else ''}\")\n",
    "    \n",
    "    return df_features, time_series_features\n",
    "\n",
    "\n",
    "def calculate_summer_apparent_temp(ta, hm):\n",
    "    \"\"\"여름철 체감온도 계산\"\"\"\n",
    "    try:\n",
    "        tw = ta * np.arctan(0.151977 * np.sqrt(hm + 8.313659)) \\\n",
    "             + np.arctan(ta + hm) \\\n",
    "             - np.arctan(hm - 1.676331) \\\n",
    "             + 0.00391838 * hm**1.5 * np.arctan(0.023101 * hm) \\\n",
    "             - 4.686035\n",
    "        return -0.2442 + 0.55399 * tw + 0.45535 * ta - 0.0022 * tw**2 + 0.00278 * tw * ta + 3.0\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_winter_apparent_temp(ta, ws):\n",
    "    \"\"\"겨울철 체감온도 계산\"\"\"\n",
    "    try:\n",
    "        v = ws * 3.6  # m/s → km/h\n",
    "        return 13.12 + 0.6215 * ta - 11.37 * v**0.16 + 0.3965 * ta * v**0.16\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def add_apparent_temp_features(df):\n",
    "    df['month'] = df['tm'].dt.month\n",
    "    df['apparent_temp'] = df.apply(lambda row:\n",
    "        calculate_summer_apparent_temp(row['ta'], row['hm']) if 5 <= row['month'] <= 9\n",
    "        else calculate_winter_apparent_temp(row['ta'], row['ws']),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def branchwise_svr_impute(df, col, time_col='tm'):\n",
    "    df = df.copy()\n",
    "    # 시간 컬럼을 숫자형으로 변환 (timestamp, 초 단위)\n",
    "    df['_time_num'] = pd.to_datetime(df[time_col]).astype(np.int64) // 10**9\n",
    "    # branch별로 SVR 보간\n",
    "    def impute_group(g):\n",
    "        return svr_impute_series(g[col], g['_time_num'])\n",
    "    # apply 결과를 원래 인덱스에 맞게 할당\n",
    "    df[col] = df.groupby('branch_id', group_keys=False).apply(impute_group)\n",
    "    df = df.drop(columns=['_time_num'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_weather_data(df):\n",
    "    # 날짜 변환\n",
    "    df['tm'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
    "    # 1. si: 08~18시가 아닐 때 -99는 0으로\n",
    "    mask_outside_8_to_18 = (~df['tm'].dt.hour.between(8, 18)) & (df['si'] == -99)\n",
    "    df.loc[mask_outside_8_to_18, 'si'] = 0\n",
    "\n",
    "    # 2. wd에서 9.9는 NaN으로\n",
    "    df['wd'] = df['wd'].replace(9.9, np.nan)\n",
    "\n",
    "    # 3. -99 처리\n",
    "    df.replace(-99, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "    # SVR 보간\n",
    "    df = df.sort_values(['branch_id', 'tm'])\n",
    "\n",
    "    numeric_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
    "\n",
    "    for branch in df['branch_id'].unique():\n",
    "        print(f\"   🏢 브랜치 {branch} SVR 보간 중...\", end=\" \")\n",
    "        \n",
    "        branch_mask = df['branch_id'] == branch\n",
    "        branch_data = df[branch_mask].copy()\n",
    "\n",
    "        # 시간 특성 생성\n",
    "        branch_data['hour'] = branch_data['tm'].dt.hour\n",
    "        branch_data['day_of_year'] = branch_data['tm'].dt.dayofyear\n",
    "        branch_data['month'] = branch_data['tm'].dt.month\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            if col in branch_data.columns:\n",
    "                missing_mask = branch_data[col].isna()\n",
    "\n",
    "                if missing_mask.sum() > 0:\n",
    "                    train_mask = ~missing_mask\n",
    "\n",
    "                    # 예측할 데이터 준비\n",
    "                    X_train = branch_data.loc[train_mask, ['hour', 'day_of_year', 'month']].values\n",
    "                    y_train = branch_data.loc[train_mask, col].values\n",
    "                    X_pred = branch_data.loc[missing_mask, ['hour', 'day_of_year', 'month']].values\n",
    "\n",
    "                    try:\n",
    "                        scaler_X = StandardScaler()\n",
    "                        scaler_y = StandardScaler()\n",
    "\n",
    "                        X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "                        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "                        svr = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "                        svr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "                        X_pred_scaled = scaler_X.transform(X_pred)\n",
    "                        y_pred_scaled = svr.predict(X_pred_scaled)\n",
    "                        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "                        # 보간 결과 반영\n",
    "                        df.loc[branch_mask & missing_mask, col] = y_pred\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\n   ⚠️ {col} SVR 실패 → 선형 보간 대체\")\n",
    "                        df.loc[branch_mask, col] = df.loc[branch_mask, col].interpolate(method='linear')\n",
    "\n",
    "                # 남은 결측 ffill/bfill로 제거\n",
    "                df.loc[branch_mask, col] = df.loc[branch_mask, col].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        print(\"✅\")\n",
    "\n",
    "    print(\"🎉 SVR 보간 완료 (조건 없이 전부 시도)\")\n",
    "    #보간후 음수나올 가능성존재\n",
    "    df.loc[df['ta'] < 0, 'ta'] = 0\n",
    "    df.loc[df['ws'] < 0, 'ws'] = 0\n",
    "\n",
    "    # 📌 파생 변수 생성\n",
    "    df['year'] = df['tm'].dt.year\n",
    "    df['month'] = df['tm'].dt.month\n",
    "    df['day'] = df['tm'].dt.day\n",
    "    df['hour'] = df['tm'].dt.hour\n",
    "    df['date'] = df['tm'].dt.date\n",
    "    df['weekday'] = df['tm'].dt.weekday\n",
    "    df['is_weekend'] = df['weekday'].isin([5,6]).astype(int)\n",
    "\n",
    "    # 🇰🇷 한국 공휴일\n",
    "    kr_holidays = holidays.KR()\n",
    "    df['is_holiday'] = df['tm'].dt.date.apply(lambda x: int(x in kr_holidays))\n",
    "\n",
    "    # 🕒 시간 지연\n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f'ta_lag_{lag}'] = df.groupby('branch_id')['ta'].shift(lag)\n",
    "        df[f'ta_lag_{lag}'] = df.groupby('branch_id')[f'ta_lag_{lag}'].transform(\n",
    "        lambda x: x.fillna(method='bfill'))\n",
    "    # 🔥 HDD / CDD\n",
    "    df['HDD18'] = np.maximum(0, 18 - df['ta'])\n",
    "    #df['CDD18'] = np.maximum(0, df['ta'] - 18)\n",
    "    df['HDD20'] = np.maximum(0, 20 - df['ta'])\n",
    "    #df['CDD20'] = np.maximum(0, df['ta'] - 20)\n",
    "\n",
    "    df['ws_diff_6h'] = df.groupby('branch_id')['ws'].transform(lambda x: x.diff(6).bfill())\n",
    "    df['ws_diff_12h'] = df.groupby('branch_id')['ws'].transform(lambda x: x.diff(12).bfill())\n",
    "    df['ws_diff_24h'] = df.groupby('branch_id')['ws'].transform(lambda x: x.diff(24).bfill())\n",
    "\n",
    "\n",
    "\n",
    "    #직접만든 체감온도\n",
    "    df = add_apparent_temp_features(df)\n",
    "\n",
    "\n",
    "    # 지점별 온도 편차\n",
    "    branch_mean = df.groupby('branch_id')['ta'].transform('mean')\n",
    "    df['branch_temp_abs_deviation'] = np.abs(df['ta'] - branch_mean)\n",
    "\n",
    "\n",
    "\n",
    "    # 이동 평균 (3시간 단위 최대 24시간 = 8개)\n",
    "    for n in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "        df[f'ta_3h_avg_{n}'] = df.groupby('branch_id')['ta'].transform(lambda x: x.rolling(n, min_periods=1).mean())\n",
    "\n",
    "    # 불쾌지수\n",
    "    df['DCI'] = 0.81 * df['ta'] + 0.01 * df['hm'] * (0.99 * df['ta'] - 14.3) + 46.3\n",
    "\n",
    "    # 풍속 냉지수 (wchi)\n",
    "    ws_kmh = df['ws'] * 3.6  # m/s -> km/h 변환\n",
    "    df['wchi'] = 13.12 + 0.6215 * df['ta'] - 11.37 * ws_kmh**0.16 + 0.3965 * df['ta'] * ws_kmh**0.16\n",
    "\n",
    "     # 풍속 고려 체감온도 (wind chill)\n",
    "    df['wind_chill'] = 13.12 + 0.6215 * df['ta'] - 11.37 * df['ws']**0.16 + 0.3965 * df['ta'] * df['ws']**0.16\n",
    "\n",
    "    # 실효온도\n",
    "    df['e'] = (df['hm'] / 100) * 6.105 * np.exp((17.27 * df['ta']) / (237.7 + df['ta']))\n",
    "    df['atemphi'] = df['ta'] + 0.33 * df['e'] - 0.70 * df['ws'] - 4.00\n",
    "\n",
    "    # 주기성 인코딩\n",
    "    df['dayofyear'] = df['tm'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['tm'].dt.day\n",
    "    df['weekofyear'] = df['tm'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    # 하루 5구간\n",
    "    def time_slot(h): return int(h // 5)\n",
    "    df['hour_slot_5'] = df['hour'].apply(time_slot)\n",
    "\n",
    "\n",
    "    def compute_fft_feature(series, n=10):\n",
    "        fft_vals = np.abs(fft(series.fillna(0)))\n",
    "        s = pd.Series(fft_vals[:n], index=pd.Index([f'fft_{i}' for i in range(n)], name='fft_idx'))\n",
    "        return s\n",
    "\n",
    "    fft_cols = ['ta', 'hm', 'ws', 'ta_chi', 'apparent_temp']\n",
    "    fft_features = []\n",
    "    branch_ids = df['branch_id'].unique()\n",
    "    fft_feature_dict = {bid: {} for bid in branch_ids}\n",
    "    for col in fft_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        for branch_id in branch_ids:\n",
    "            arr = df.loc[df['branch_id'] == branch_id, col].fillna(0).values\n",
    "            fft_vals = np.abs(fft(arr))[:10]\n",
    "            for i, val in enumerate(fft_vals):\n",
    "                fft_feature_dict[branch_id][f'Nph_{col}_{i}'] = val\n",
    "                \n",
    "    # DataFrame으로 변환\n",
    "    fft_features_df = pd.DataFrame.from_dict(fft_feature_dict, orient='index')\n",
    "    # 원본 df와 merge\n",
    "    df = df.merge(fft_features_df, left_on='branch_id', right_index=True, how='left')\n",
    "\n",
    "    # 기온 차분\n",
    "    df['ta_diff_6h'] = df.groupby('branch_id')['ta'].transform(lambda x: x.diff(6).bfill())\n",
    "    df['ta_diff_12h'] = df.groupby('branch_id')['ta'].transform(lambda x: x.diff(12).bfill())\n",
    "    df['ta_diff_24h'] = df.groupby('branch_id')['ta'].transform(lambda x: x.diff(24).bfill())\n",
    "\n",
    "\n",
    "    # 일교차\n",
    "    df['day_ta_max'] = df.groupby(['branch_id', df['tm'].dt.date])['ta'].transform('max')\n",
    "    df['day_ta_min'] = df.groupby(['branch_id', df['tm'].dt.date])['ta'].transform('min')\n",
    "    df['daily_range'] = df['day_ta_max'] - df['day_ta_min']\n",
    "\n",
    "    # 일교차 변화량\n",
    "    df['daily_range_shift'] = df.groupby('branch_id')['daily_range'].shift(1).bfill()\n",
    "    df['daily_range_shift_ta'] = df['daily_range_shift']*df['ta']\n",
    "\n",
    "    #ws변화량\n",
    "    df['day_ws_max'] = df.groupby(['branch_id', df['tm'].dt.date])['ws'].transform('max')\n",
    "    df['day_ws_min'] = df.groupby(['branch_id', df['tm'].dt.date])['ws'].transform('min')\n",
    "    df['daily_range_ws'] = df['day_ws_max'] - df['day_ws_min']\n",
    "\n",
    "    # 일교차 변화량\n",
    "    df['daily_range_shift_ws'] = df.groupby('branch_id')['daily_range_ws'].shift(1).bfill()\n",
    "\n",
    "    # 피크타임1\n",
    "    df['peak_time1'] = 0\n",
    "    df.loc[(df['hour'] >= 0) & (df['hour'] <= 6), 'peak_time1'] = 1\n",
    "    df.loc[(df['hour'] > 6) & (df['hour'] <= 11), 'peak_time1'] = 2\n",
    "    df.loc[(df['hour'] > 11) & (df['hour'] <= 18), 'peak_time1'] = 3\n",
    "    df.loc[(df['hour'] > 18) & (df['hour'] <= 23), 'peak_time1'] = 4\n",
    "\n",
    "    # 피크타임2\n",
    "    df['peak_time2'] = 0\n",
    "    df.loc[(df['hour'] >= 2) & (df['hour'] <= 10), 'peak_time2'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # heating season\n",
    "    df['heating_season'] = df['month'].isin([10,11,12,1, 2, 3,4]).astype(int)\n",
    "\n",
    "    # 온도 범주화\n",
    "    df['temp_category20'] = pd.cut(df['ta'], bins=[-np.inf, 20, np.inf], labels=['low', 'high'])\n",
    "    df['temp_category18'] = pd.cut(df['ta'], bins=[-np.inf, 18, np.inf], labels=['low', 'high'])\n",
    "    df['temp_category16'] = pd.cut(df['ta'], bins=[-np.inf, 16, np.inf], labels=['low', 'high'])\n",
    "\n",
    "    # 오전/오후\n",
    "    df['afternoon'] = (df['hour'] >= 12).astype(int)\n",
    "\n",
    "    # 계절\n",
    "    def get_season(month):\n",
    "        return {\n",
    "            12: 'winter', 1: 'winter', 2: 'winter',\n",
    "            3: 'spring', 4: 'spring', 5: 'spring',\n",
    "            6: 'summer', 7: 'summer', 8: 'summer',\n",
    "            9: 'fall', 10: 'fall', 11: 'fall'\n",
    "        }.get(month, 'unknown')\n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "\n",
    "    # 한파 주의보/경보\n",
    "    df['cold_watch'] = (df['ta'] <= -12).astype(int)  # 주의보\n",
    "    df['cold_warning'] = (df['ta'] <= -15).astype(int)  # 경보\n",
    "    # 시계열 분해 특성 생성 (heat_demand 제외)\n",
    "    print(\"🚀 STL 시계열 분해 시작...\")\n",
    "    df, ts_features = create_time_series_features(df, target_cols=['ta', 'ws'])\n",
    "\n",
    "\n",
    "    # 변환 대상 변수\n",
    "    col = 'ta'\n",
    "    '''\n",
    "    df['ta_boxcox'] = np.nan\n",
    "    df['ta_boxcox_lambda'] = np.nan\n",
    "    df['ta_boxcox_shift'] = np.nan  # shift 값도 저장\n",
    "    for branch, group in df.groupby('branch_id'):\n",
    "        col = 'ta'\n",
    "        min_val = group[col].min()\n",
    "        if min_val <= 0:\n",
    "            shift = abs(min_val) + 1e-4\n",
    "        else:\n",
    "            shift = 0\n",
    "        shifted = group[col] + shift\n",
    "        shifted = shifted.dropna()\n",
    "        if shifted.nunique() > 1 and len(shifted) >= 2:\n",
    "            transformed, fitted_lambda = boxcox(shifted)\n",
    "            df.loc[shifted.index, 'ta_boxcox'] = transformed\n",
    "            df.loc[shifted.index, 'ta_boxcox_lambda'] = fitted_lambda\n",
    "            df.loc[shifted.index, 'ta_boxcox_shift'] = shift\n",
    "        else:\n",
    "            df.loc[group.index, 'ta_boxcox'] = np.nan\n",
    "            df.loc[group.index, 'ta_boxcox_lambda'] = np.nan\n",
    "            df.loc[group.index, 'ta_boxcox_shift'] = shift\n",
    "\n",
    "\n",
    "    '''\n",
    "    df = df.drop(columns=['date'])\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "#상호작용 처리못함\n",
    "#군집화된 전처리 못함\n",
    "\n",
    "\n",
    "#정규화 일단 min max +원핫인코딩\n",
    "def scale_encode(df):\n",
    "    cat_cols = [\n",
    "        'peak_time1', 'peak_time2', 'heating_season','hour_slot_5',\n",
    "        'temp_category16', 'temp_category18', 'temp_category20','afternoon', 'season','month','day','hour']\n",
    "\n",
    "    # 범주형 변수 category화\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    # 원-핫 인코딩\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # 연속형 변수만 추출 (타겟, 날짜 등 제외)\n",
    "    exclude_cols = ['heat_demand','peak_time1', 'peak_time2', 'heating_season','hour_slot_5',\n",
    "        'temp_category16', 'temp_category18', 'temp_category20','afternoon', 'season','month','day','hour']\n",
    "    num_cols = [col for col in df.columns\n",
    "                if (df[col].dtype in [np.float64, np.int64]) and (col not in exclude_cols)]\n",
    "\n",
    "    # MinMaxScaler 적용\n",
    "    scaler = MinMaxScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df_train = preprocess_weather_data(df_train)\n",
    "df_test = preprocess_weather_data(df_test)\n",
    "\n",
    "\n",
    "df_train = scale_encode(df_train)\n",
    "df_test = scale_encode(df_test)\n",
    "\n",
    "df_train.to_csv('df_train_prescale.csv', index=True)\n",
    "df_test.to_csv('df_test_prescale.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_train_prescale.csv')\n",
    "df_test = pd.read_csv('df_test_prescale.csv')\n",
    "df_train = df_train.sort_values(['branch_id', 'tm'])\n",
    "df_test = df_test.sort_values(['branch_id', 'tm'])\n",
    "\n",
    "\n",
    "\n",
    "df_train = df_train.drop(columns=['year'])\n",
    "df_train = df_train.drop(columns=['Unnamed: 0'])\n",
    "df_test = df_test.drop(columns=['year'])\n",
    "df_test = df_test.drop(columns=['Unnamed: 0'])\n",
    "df_train = df_train.set_index('tm')\n",
    "df_test = df_test.set_index('tm')\n",
    "df_train = df_train.sort_index()\n",
    "df_test = df_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_3fold_pipeline_with_residual(df_train, df_test, target_col='heat_demand'):\n",
    "\n",
    "    features = [col for col in df_train.columns if col != target_col]\n",
    "    X = df_train[features]\n",
    "    y = df_train[target_col]\n",
    "\n",
    "    n = len(df_train)\n",
    "    fold_size = n // 3\n",
    "\n",
    "    val_rmses = []\n",
    "    test_preds = []\n",
    "\n",
    "    print(f\"전체 데이터 길이: {n}, Fold 크기: {fold_size}\\n\")\n",
    "\n",
    "    for fold in range(2):  # Fold 0, 1 수행 (3번째는 테스트용 데이터 분리)\n",
    "        train_end = fold_size * (fold + 1)\n",
    "        val_end = fold_size * (fold + 2)\n",
    "\n",
    "        X_train = X.iloc[:train_end]\n",
    "        y_train = y.iloc[:train_end]\n",
    "        X_val = X.iloc[train_end:val_end]\n",
    "        y_val = y.iloc[train_end:val_end]\n",
    "\n",
    "        print(f\"===== Fold {fold+1} =====\")\n",
    "        print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}\")\n",
    "\n",
    "        # 1) LightGBM 베이지안 최적화 함수\n",
    "        def lgb_objective(trial):\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),\n",
    "                'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "                'n_estimators': 1000,\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            model = lgb.LGBMRegressor(**params)\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "            )\n",
    "            val_pred = model.predict(X_val)\n",
    "            return np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "\n",
    "        lgb_study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        lgb_study.optimize(lgb_objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "        best_lgb_params = lgb_study.best_params\n",
    "        best_lgb_params.update({\n",
    "            'objective': 'huber',\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'n_estimators': 1000,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        })\n",
    "\n",
    "        # 2) LightGBM 최적 모델 학습\n",
    "        lgb_model = lgb.LGBMRegressor(**best_lgb_params)\n",
    "        lgb_model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    "        )\n",
    "\n",
    "        val_pred_lgb = lgb_model.predict(X_val)\n",
    "        val_rmse_lgb = np.sqrt(mean_squared_error(y_val, val_pred_lgb))\n",
    "        print(f\"LightGBM Fold {fold+1} Validation RMSE: {val_rmse_lgb:.4f}\")\n",
    "\n",
    "        # 3) 잔차 계산\n",
    "        residual_train = y_train - lgb_model.predict(X_train)\n",
    "        residual_val = y_val - val_pred_lgb\n",
    "\n",
    "        # 4) XGBoost 베이지안 최적화 함수 (fold별로 동일하게 분할)\n",
    "        def xgb_objective(trial):\n",
    "            params = {\n",
    "                'objective': 'reg:pseudohubererror',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "            model.fit(\n",
    "                X_train, residual_train,\n",
    "                eval_set=[(X_val, residual_val)],\n",
    "                verbose=0\n",
    "            )\n",
    "            val_pred = model.predict(X_val)\n",
    "            return np.sqrt(mean_squared_error(residual_val, val_pred))\n",
    "\n",
    "        xgb_study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        xgb_study.optimize(xgb_objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "        best_xgb_params = xgb_study.best_params\n",
    "        best_xgb_params.update({\n",
    "            'objective': 'reg:pseudohubererror',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        })\n",
    "\n",
    "        # 5) XGBoost 최적 모델 학습 (잔차 예측용, fold별로)\n",
    "        xgb_model = xgb.XGBRegressor(**best_xgb_params)\n",
    "        xgb_model.fit(\n",
    "            X_train, residual_train,\n",
    "            eval_set=[(X_val, residual_val)],\n",
    "            verbose=100\n",
    "        )\n",
    "\n",
    "        val_pred_residual = xgb_model.predict(X_val)\n",
    "        val_pred_final = val_pred_lgb + val_pred_residual\n",
    "        val_rmse_final = np.sqrt(mean_squared_error(y_val, val_pred_final))\n",
    "        print(f\"Residual Stacking Fold {fold+1} Validation RMSE: {val_rmse_final:.4f}\")\n",
    "\n",
    "        val_rmses.append(val_rmse_final)\n",
    "\n",
    "        # fold별로 test 예측 저장\n",
    "        test_pred_lgb = lgb_model.predict(df_test[features])\n",
    "        test_pred_residual = xgb_model.predict(df_test[features])\n",
    "        test_pred_fold = test_pred_lgb + test_pred_residual\n",
    "        test_preds.append(test_pred_fold)\n",
    "\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "    avg_val_rmse = np.mean(val_rmses)\n",
    "    avg_test_pred = np.mean(test_preds, axis=0)\n",
    "\n",
    "    print(f\"\\n최종 평균 Validation RMSE: {avg_val_rmse:.4f}\")\n",
    "\n",
    "    df_test[target_col] = avg_test_pred\n",
    "\n",
    "    return {\n",
    "        'val_rmse': avg_val_rmse,\n",
    "        'val_rmses': val_rmses,\n",
    "        'test_pred': avg_test_pred,\n",
    "        'test_index': df_test.index\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_rmse_results = {}\n",
    "test_pred_dict = {}\n",
    "\n",
    "branch_ids = df_train['branch_id'].unique()\n",
    "\n",
    "for branch in branch_ids:\n",
    "    train_branch = df_train[df_train['branch_id'] == branch].copy()\n",
    "    test_branch = df_test[df_test['branch_id'] == branch].copy()\n",
    "    \n",
    "    # branch_id는 모델에 불필요하면 제거\n",
    "    train_branch = train_branch.drop(columns=['branch_id'])\n",
    "    test_branch = test_branch.drop(columns=['branch_id'])\n",
    "    \n",
    "    target_col = 'heat_demand'\n",
    "    \n",
    "    results = run_3fold_pipeline_with_residual(train_branch, test_branch, target_col)\n",
    "    \n",
    "    branch_rmse_results[branch] = {\n",
    "        'val_rmse': results['val_rmse']\n",
    "    }\n",
    "    \n",
    "    test_pred_dict[branch] = pd.DataFrame({\n",
    "        'branch_ID': branch,\n",
    "        'TM': results['test_index'],\n",
    "        'heat_demand': results['test_pred']\n",
    "    }).set_index('TM')\n",
    "\n",
    "\n",
    "# test_pred_dict의 모든 branch 결과를 하나의 DataFrame으로 병합\n",
    "merged_df = pd.concat(test_pred_dict.values()).reset_index()\n",
    "\n",
    "\n",
    "# CSV 파일로 저장\n",
    "merged_df.to_csv('250464_test.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('250464_test.csv')\n",
    "df1['TM'] = pd.to_datetime(df1['TM'])\n",
    "df1 = df1.sort_values(by=['branch_ID', 'TM']).reset_index(drop=True)\n",
    "df2 = pd.read_csv('test_heat.csv')\n",
    "df2['heat_demand'] = df1['heat_demand'].round(1)\n",
    "df2.to_csv('250464.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#huber지표랑 교차검증 순차로하는식으로 3fold로해서 연도별로 짜름 까지 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
