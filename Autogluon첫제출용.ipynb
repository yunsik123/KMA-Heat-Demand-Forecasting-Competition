{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dB547DkSSMNO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.metrics import  mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train_heat.csv\")\n",
        "df_test = pd.read_csv(\"test_heat.csv\")\n",
        "#열이름빼기\n",
        "df_train.columns = df_train.columns.str.replace('train_heat.', '', regex=False)\n",
        "#Unnamed:0제거\n",
        "df_train = df_train.drop(columns=[\"Unnamed: 0\"])\n",
        "df_test.columns = [\n",
        "    \"tm\", \"branch_id\", \"ta\", \"wd\", \"ws\",\n",
        "    \"rn_day\", \"rn_hr1\", \"hm\", \"si\", \"ta_chi\",\"heat_demand\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#체감온도 직접만든 변수\n",
        "def calc_wind_chill(Ta, RH, WS):\n",
        "    # 겨울철 조건: 기온 10℃ 이하, 풍속 1.3m/s 이상\n",
        "    cond = (Ta <= 10) & (WS >= 1.3)\n",
        "    Tw = np.full_like(Ta, np.nan, dtype=np.float64)\n",
        "    # 공식 적용\n",
        "    Ta_ = Ta[cond]\n",
        "    RH_ = RH[cond]\n",
        "    WS_ = WS[cond]\n",
        "    # 공식 (수정된 식)\n",
        "    Tw_calc = (\n",
        "        Ta_ * np.arctan(0.151977 * np.sqrt(RH_ + 8.313659))\n",
        "        + np.arctan(Ta_ + RH_)\n",
        "        - np.arctan(RH_ - 1.67633)\n",
        "        + 0.00391838 * RH_ ** 1.5 * np.arctan(0.023101 * RH_)\n",
        "        - 4.686035\n",
        "    )\n",
        "    # 겨울형 기간 동안 산출된 체감온도가 기온보다 높으면 기온과 같게\n",
        "    Tw_calc = np.where(Tw_calc > Ta_, Ta_, Tw_calc)\n",
        "    Tw[cond] = Tw_calc\n",
        "    return Tw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DG9Mm5D7VMIb"
      },
      "outputs": [],
      "source": [
        "def preprocess_df(df):\n",
        "    # 접두사 제거: 'train_heat.' 컬럼명 변경\n",
        "    df = df.rename(columns=lambda x: x.replace('train_heat.', '') if 'train_heat.' in x else x)\n",
        "\n",
        "    # 결측치 처리 (-99, -9.9)\n",
        "    df = df.replace(-99, np.nan)\n",
        "    if 'wd' in df.columns:\n",
        "        df['wd'] = df['wd'].replace(-9.9, np.nan)\n",
        "\n",
        "    # 시간 전처리\n",
        "    df['month'] = df['tm'].astype(str).str[4:6].astype(int)\n",
        "    df['hour'] = df['tm'].astype(str).str[8:10].astype(int)\n",
        "    df['date'] = pd.to_datetime(df['tm'].astype(str).str[:8])\n",
        "    df['weekday'] = df['date'].dt.weekday\n",
        "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
        "    df['tm'] = pd.to_datetime(df['tm'].astype(str), format='%Y%m%d%H')\n",
        "    df = df.sort_values('tm').set_index('tm')\n",
        "    if 'si' in df.columns:\n",
        "        df.loc[~df['hour'].between(8, 18), 'si'] = 0\n",
        "    # 계절 구분\n",
        "    df['heating_season'] = df['month'].apply(lambda x: 1 if x in [10,11,12,1,2,3,4] else 0)\n",
        "    df['temp_category'] = df['ta'].apply(lambda x: 1 if x >= 20 else 0)\n",
        "\n",
        "    # 피크타임 함수\n",
        "    def peak_time_category(hour):\n",
        "        if 0 <= hour <= 6:\n",
        "            return 0  # 심야\n",
        "        elif 6 < hour <= 11:\n",
        "            return 1  # 오전\n",
        "        elif 11 < hour <= 18:\n",
        "            return 2  # 오후\n",
        "        else:\n",
        "            return 3  # 저녁\n",
        "\n",
        "    df['peak_time'] = df['hour'].apply(peak_time_category)\n",
        "\n",
        "    # lag feature (1,2,3시간)\n",
        "    for lag in [1,2,3]:\n",
        "        df[f'ta_lag_{lag}'] = df['ta'].shift(lag).interpolate(method='linear')\n",
        "\n",
        "    # HDD, CDD\n",
        "    base_temp = 18.0\n",
        "    df['HDD'] = (base_temp - df['ta']).clip(lower=0)\n",
        "    df['CDD'] = (df['ta'] - base_temp).clip(lower=0)\n",
        "\n",
        "    # 편차\n",
        "    df['branch_temp_abs_deviation'] = (\n",
        "        df['ta'] - df.groupby('branch_id')['ta'].transform('mean')\n",
        "    ).abs()\n",
        "\n",
        "    # 변수별 diff 및 24시간 이동평균\n",
        "    vars_to_process = ['ta', 'si', 'ta_chi', 'ws', 'wd', 'rn_day', 'rn_hr1']\n",
        "    for var in vars_to_process:\n",
        "        if var in df.columns:\n",
        "            df[f'{var}_diff'] = df[var].diff().fillna(0)\n",
        "            df[f'{var}_ma24'] = df[var].rolling(window=24, min_periods=1).mean()\n",
        "\n",
        "    # 누적 강수량(최근 3/6/12/24시간)\n",
        "    for h in [3,6,12,24]:\n",
        "        if 'rn_hr1' in df.columns:\n",
        "            df[f'rn_hr1_sum{h}'] = df['rn_hr1'].rolling(h, min_periods=1).sum()\n",
        "\n",
        "    # 최고/최저 기온(최근 6/12/24시간)\n",
        "    for h in [6,12,24]:\n",
        "        if 'ta' in df.columns:\n",
        "            df[f'ta_max{h}'] = df['ta'].rolling(h, min_periods=1).max()\n",
        "            df[f'ta_min{h}'] = df['ta'].rolling(h, min_periods=1).min()\n",
        "\n",
        "    # 네가 만든 체감온도 공식으로 계산한 변수 추가\n",
        "    df['ta_chi_formula'] = calc_wind_chill(df['ta'].values, df['hm'].values, df['ws'].values)\n",
        "\n",
        "    # 체감온도 - 실제온도 차이 변수\n",
        "    if 'ta_chi' in df.columns and 'ta' in df.columns:\n",
        "        df['diff_ta_chi'] = df['ta_chi'] - df['ta']\n",
        "\n",
        "    # 풍속 급변(2-step 차분)\n",
        "    if 'ws' in df.columns:\n",
        "        df['ws_diff2'] = df['ws'].diff(2).fillna(0)\n",
        "\n",
        "    # 당일 누적 강수량\n",
        "    if 'rn_day' in df.columns:\n",
        "        df['rn_day_cumsum'] = df['rn_day'].cumsum()\n",
        "\n",
        "    # 전일 평균/최고/최저 기온\n",
        "    if 'ta' in df.columns:\n",
        "        df['ta_yesterday_avg'] = df['ta'].shift(24).rolling(24).mean()\n",
        "        df['ta_yesterday_max'] = df['ta'].shift(24).rolling(24).max()\n",
        "        df['ta_yesterday_min'] = df['ta'].shift(24).rolling(24).min()\n",
        "\n",
        "    # 임계치 이탈 플래그\n",
        "    if 'ta' in df.columns:\n",
        "        df['cold_flag'] = (df['ta'] < 5).astype(int)\n",
        "        df['hot_flag'] = (df['ta'] > 25).astype(int)\n",
        "\n",
        "    # 최근 6시간 기온 표준편차\n",
        "    df['ta_std6'] = df['ta'].rolling(6, min_periods=1).std().fillna(0)\n",
        "\n",
        "    # 최근 6시간 풍속 표준편차\n",
        "    df['ws_std6'] = df['ws'].rolling(6, min_periods=1).std().fillna(0)\n",
        "\n",
        "    # 최근 24시간 내 강수 발생 여부 (이진 플래그)\n",
        "    df['rain_flag_24h'] = (df['rn_hr1'].rolling(24, min_periods=1).sum() > 0).astype(int)\n",
        "\n",
        "    # 월별 평균 기온과의 차이\n",
        "    df['monthly_avg_ta'] = df.groupby('month')['ta'].transform('mean')\n",
        "    df['ta_monthly_dev'] = df['ta'] - df['monthly_avg_ta']\n",
        "\n",
        "    df['ta_ma3'] = df['ta'].rolling(3, min_periods=1).mean()\n",
        "    df['ta_max3'] = df['ta'].rolling(3, min_periods=1).max()\n",
        "    df['ta_min3'] = df['ta'].rolling(3, min_periods=1).min()\n",
        "    df['ta_lastweek'] = df['ta'].shift(24*7)\n",
        "    df['hourly_avg_ta'] = df.groupby('hour')['ta'].transform('mean')\n",
        "    df['ta_hourly_dev'] = df['ta'] - df['hourly_avg_ta']\n",
        "    df['ta_yesterday'] = df['ta'].shift(24)\n",
        "    df['ta_trend12'] = df['ta'] - df['ta'].shift(12)\n",
        "\n",
        "    # 결측치 보간 및 0으로 채우기\n",
        "    for col in df.columns[df.isnull().any()]:\n",
        "        df[col] = df[col].interpolate(method='linear')\n",
        "    for col in df.columns[df.isnull().any()]:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'tm'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'tm'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_trainval = \u001b[43mpreprocess_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_test = preprocess_df(df_test)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 피처 정의\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mpreprocess_df\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      8\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mwd\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mwd\u001b[39m\u001b[33m'\u001b[39m].replace(-\u001b[32m9.9\u001b[39m, np.nan)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 시간 전처리\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).str[\u001b[32m4\u001b[39m:\u001b[32m6\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     12\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mtm\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str[\u001b[32m8\u001b[39m:\u001b[32m10\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     13\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mtm\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str[:\u001b[32m8\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'tm'"
          ]
        }
      ],
      "source": [
        "df_trainval = preprocess_df(df_train)\n",
        "df_test = preprocess_df(df_test)\n",
        "\n",
        "# 피처 정의\n",
        "categorical_cols = [\n",
        "    'branch_id', 'month', 'weekday', 'is_weekend', 'heating_season',\n",
        "    'temp_category', 'peak_time', 'cold_flag', 'hot_flag'\n",
        "]\n",
        "target = 'heat_demand'\n",
        "\n",
        "numerical_cols = [\n",
        "    'hour', 'ta', 'si', 'ta_chi', 'ws', 'wd', 'rn_day', 'rn_hr1', 'hm',\n",
        "    'ta_lag_1', 'ta_lag_2', 'ta_lag_3', 'HDD', 'CDD', 'branch_temp_abs_deviation',\n",
        "    'ta_diff', 'si_diff', 'ta_chi_diff', 'ws_diff', 'wd_diff', 'rn_day_diff', 'rn_hr1_diff',\n",
        "    'ta_ma24', 'si_ma24', 'ta_chi_ma24', 'ws_ma24', 'wd_ma24', 'rn_day_ma24', 'rn_hr1_ma24',\n",
        "    'rn_hr1_sum3', 'rn_hr1_sum6', 'rn_hr1_sum12', 'rn_hr1_sum24',\n",
        "    'ta_max6', 'ta_min6', 'ta_max12', 'ta_min12', 'ta_max24', 'ta_min24',\n",
        "    'ta_chi_formula', 'diff_ta_chi', 'ws_diff2', 'rn_day_cumsum',\n",
        "    'ta_yesterday_avg', 'ta_yesterday_max', 'ta_yesterday_min',\n",
        "    'ta_std6', 'ws_std6', 'rain_flag_24h', 'monthly_avg_ta', 'ta_monthly_dev',\n",
        "    'ta_ma3', 'ta_max3', 'ta_min3', 'ta_lastweek',\n",
        "    'hourly_avg_ta', 'ta_hourly_dev', 'ta_yesterday', 'ta_trend12'\n",
        "]\n",
        "\n",
        "features = categorical_cols + numerical_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TibJhYTKbUVC",
        "outputId": "9d43e9e1-8dd8-4454-dee5-4c78c8890768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Fold 1 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels_fold1\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.0\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.19045\n",
            "CPU Count:          12\n",
            "Memory Avail:       3.96 GB / 31.74 GB (12.5%)\n",
            "Disk Space Avail:   244.59 GB / 476.28 GB (51.4%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"c:\\Users\\Admin\\Desktop\\신윤식\\기상청공모전\\data\\AutogluonModels_fold1\"\n",
            "Train Data Rows:    83221\n",
            "Train Data Columns: 86\n",
            "Tuning Data Rows:    83216\n",
            "Tuning Data Columns: 86\n",
            "Label Column:       heat_demand\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    3977.54 MB\n",
            "\tTrain Data (Original)  Memory Usage: 87.46 MB (2.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 25 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('bool', [])  : 19 | ['branch_id_A', 'branch_id_B', 'branch_id_C', 'branch_id_D', 'branch_id_E', ...]\n",
            "\t\t('float', []) : 59 | ['hour', 'ta', 'si', 'ta_chi', 'ws', ...]\n",
            "\t\t('int', [])   :  8 | ['month', 'weekday', 'is_weekend', 'heating_season', 'temp_category', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 58 | ['hour', 'ta', 'si', 'ta_chi', 'ws', ...]\n",
            "\t\t('int', [])       :  3 | ['month', 'weekday', 'peak_time']\n",
            "\t\t('int', ['bool']) : 25 | ['rain_flag_24h', 'is_weekend', 'heating_season', 'temp_category', 'cold_flag', ...]\n",
            "\t0.9s = Fit runtime\n",
            "\t86 features in original data used to generate 86 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 80.79 MB (2.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2398.64s of the 3598.86s of remaining time.\n",
            "\t-112.2555\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.15s\t = Training   runtime\n",
            "\t12.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2373.85s of the 3574.06s of remaining time.\n",
            "\t-112.2573\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t13.29s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2347.22s of the 3547.43s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.09%)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "n_splits = 5\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(df_trainval)):\n",
        "    print(f\"\\n===== Fold {fold+1} =====\")\n",
        "\n",
        "    df_train = df_trainval.iloc[train_idx].copy()\n",
        "    df_val = df_trainval.iloc[val_idx].copy()\n",
        "\n",
        "    # 실제 존재하는 범주형 컬럼만 사용\n",
        "    actual_categorical_cols = [col for col in categorical_cols if col in df_train.columns]\n",
        "\n",
        "    # prefix 없이 get_dummies 사용 (가장 안전)\n",
        "    if actual_categorical_cols:\n",
        "        df_train_cat = pd.get_dummies(df_train[actual_categorical_cols])\n",
        "        df_val_cat = pd.get_dummies(df_val[actual_categorical_cols])\n",
        "        df_test_cat = pd.get_dummies(df_test[actual_categorical_cols])\n",
        "\n",
        "        # df_train 기준으로 컬럼 정렬 및 누락 컬럼 0 채우기\n",
        "        df_val_cat = df_val_cat.reindex(columns=df_train_cat.columns, fill_value=0)\n",
        "        df_test_cat = df_test_cat.reindex(columns=df_train_cat.columns, fill_value=0)\n",
        "    else:\n",
        "        df_train_cat = pd.DataFrame(index=df_train.index)\n",
        "        df_val_cat = pd.DataFrame(index=df_val.index)\n",
        "        df_test_cat = pd.DataFrame(index=df_test.index)\n",
        "\n",
        "    # 연속형 변수 스케일링\n",
        "    scaler = MinMaxScaler()\n",
        "    df_train_num_scaled = pd.DataFrame(scaler.fit_transform(df_train[numerical_cols]), columns=numerical_cols)\n",
        "    df_val_num_scaled = pd.DataFrame(scaler.transform(df_val[numerical_cols]), columns=numerical_cols)\n",
        "    df_test_num_scaled = pd.DataFrame(scaler.transform(df_test[numerical_cols]), columns=numerical_cols)\n",
        "\n",
        "    # 최종 feature set 결합\n",
        "    df_train_final = pd.concat([df_train_num_scaled.reset_index(drop=True), df_train_cat.reset_index(drop=True)], axis=1)\n",
        "    df_val_final = pd.concat([df_val_num_scaled.reset_index(drop=True), df_val_cat.reset_index(drop=True)], axis=1)\n",
        "    df_test_final = pd.concat([df_test_num_scaled.reset_index(drop=True), df_test_cat.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # target 추가\n",
        "    df_train_final[target] = df_train[target].reset_index(drop=True)\n",
        "    df_val_final[target] = df_val[target].reset_index(drop=True)\n",
        "\n",
        "    features_final = df_train_final.columns.drop(target)\n",
        "\n",
        "    # 모델 학습\n",
        "    predictor = TabularPredictor(\n",
        "        label=target,\n",
        "        problem_type='regression',\n",
        "        path=f\"AutogluonModels_fold{fold+1}\"\n",
        "    ).fit(\n",
        "        train_data=df_train_final,\n",
        "        tuning_data=df_val_final,\n",
        "        presets='best_quality',\n",
        "        use_bag_holdout=True,\n",
        "        ag_args_fit={'num_gpus': 0}\n",
        "    )\n",
        "\n",
        "    # 검증 RMSE\n",
        "    y_val_true = df_val_final[target]\n",
        "    y_val_pred = predictor.predict(df_val_final[features_final])\n",
        "    val_rmse = mean_squared_error(y_val_true, y_val_pred, squared=False)\n",
        "\n",
        "    # 테스트 RMSE (target 컬럼이 있다면)\n",
        "    if target in df_test.columns and df_test[target].notnull().all():\n",
        "        y_test_true = df_test[target]\n",
        "        y_test_pred = predictor.predict(df_test_final[features_final])\n",
        "        test_rmse = mean_squared_error(y_test_true, y_test_pred, squared=False)\n",
        "    else:\n",
        "        test_rmse = None\n",
        "\n",
        "    print(f\"Fold {fold+1} | Val RMSE: {val_rmse:.4f} | Test RMSE: {test_rmse if test_rmse is not None else 'N/A'}\")\n",
        "\n",
        "    # 마지막 fold 예측 저장\n",
        "    if fold == n_splits - 1:\n",
        "        df_test[target] = predictor.predict(df_test_final[features_final])\n",
        "        last_val_true = y_val_true\n",
        "        last_val_pred = y_val_pred\n",
        "        last_val_index = df_val.index  # 시계열 index 기준\n",
        "\n",
        "    results.append({\n",
        "        'fold': fold+1,\n",
        "        'val_rmse': val_rmse,\n",
        "        'test_rmse': test_rmse\n",
        "    })\n",
        "\n",
        "# 전체 Fold 결과 출력\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n===== 전체 Fold 결과 =====\")\n",
        "print(results_df)\n",
        "\n",
        "# 예측 결과 저장\n",
        "df_test.to_csv('df_test_with_predicted_heat_demand.csv', index=False)\n",
        "print(\"df_test_with_predicted_heat_demand.csv 파일이 저장되었습니다.\")\n",
        "\n",
        "# 마지막 Fold 시각화\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.plot(last_val_index, last_val_true.values, label='실제값 (Validation True)', linewidth=2)\n",
        "plt.plot(last_val_index, last_val_pred.values, label='예측값 (Validation Predicted)', alpha=0.7)\n",
        "plt.title('마지막 Fold 검증셋 실제값 vs 예측값')\n",
        "plt.xlabel('Time Index')\n",
        "plt.ylabel('Heat Demand')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksEfF0yzkgUf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_val_final' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 마지막 fold의 검증 데이터 준비\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_val = \u001b[43mdf_val_final\u001b[49m[features_final]\n\u001b[32m      3\u001b[39m y_val = df_val_final[target]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Autogluon predictor는 scikit-learn API를 직접 지원하지 않으므로, 예측 함수를 래핑\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'df_val_final' is not defined"
          ]
        }
      ],
      "source": [
        "# 마지막 fold의 검증 데이터 준비\n",
        "X_val = df_val_final[features_final]\n",
        "y_val = df_val_final[target]\n",
        "\n",
        "# Autogluon predictor는 scikit-learn API를 직접 지원하지 않으므로, 예측 함수를 래핑\n",
        "class PredictorWrapper:\n",
        "    def __init__(self, predictor, features):\n",
        "        self.predictor = predictor\n",
        "        self.features = features\n",
        "    def predict(self, X):\n",
        "        # DataFrame이 들어오면 features만 추출\n",
        "        return self.predictor.predict(X[self.features])\n",
        "\n",
        "# 래퍼 생성\n",
        "wrapped_predictor = PredictorWrapper(predictor, features_final)\n",
        "\n",
        "# permutation importance 계산\n",
        "result = permutation_importance(\n",
        "    wrapped_predictor,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    n_repeats=10,\n",
        "    random_state=42,\n",
        "    scoring='neg_root_mean_squared_error'\n",
        ")\n",
        "\n",
        "# 중요도 정렬 및 시각화\n",
        "sorted_idx = result.importances_mean.argsort()[::-1]\n",
        "top_n = 20  # 상위 20개만 시각화\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(\n",
        "    np.array(features_final)[sorted_idx][:top_n][::-1],\n",
        "    result.importances_mean[sorted_idx][:top_n][::-1],\n",
        "    xerr=result.importances_std[sorted_idx][:top_n][::-1],\n",
        "    color='skyblue'\n",
        ")\n",
        "plt.xlabel('Permutation Importance (Decrease in RMSE)')\n",
        "plt.title('Permutation Feature Importance (Top 20)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 중요도 점수 표 출력\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': np.array(features_final)[sorted_idx],\n",
        "    'importance_mean': result.importances_mean[sorted_idx],\n",
        "    'importance_std': result.importances_std[sorted_idx]\n",
        "})\n",
        "print(\"\\n===== Permutation Importance (Top 20) =====\")\n",
        "print(importance_df.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JuFxe1okgSX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VicylNUMkgQB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtyNHftFkgNf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKP21r-_kgLA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP5RXAzjkgI6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2gMn3pVkgB1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9kCuBw9jJL3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
