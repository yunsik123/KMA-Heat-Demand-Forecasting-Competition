import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import holidays
from scipy.fftpack import fft#í‘¸ë¦¬ì— ë³€í™˜ì„ ìœ„í•œ ì½”ë“œì…ë‹ˆë‹¤.
from scipy.stats import boxcox#ë°•ìŠ¤ì½•ìŠ¤ ë³€í™˜ì„ ìœ„í•œ ì½”ë“œì„


from sklearn.preprocessing import MinMaxScaler

df_train = pd.read_csv("train_heat.csv")
df_test = pd.read_csv("test_heat.csv")
#ì—´ì´ë¦„ë¹¼ê¸°
df_train.columns = df_train.columns.str.replace('train_heat.', '', regex=False)
#Unnamed:0ì œê±°
df_train = df_train.drop(columns=["Unnamed: 0"])
#testë°ì´í„° ì—´ì´ë¦„ ë°”ê¾¸ê¸°
df_test.columns = [
    "tm", "branch_id", "ta", "wd", "ws",
    "rn_day", "rn_hr1", "hm", "si", "ta_chi","heat_demand"]



def calculate_summer_apparent_temp(ta, hm):
    """ì—¬ë¦„ì²  ì²´ê°ì˜¨ë„ ê³„ì‚°"""
    try:
        tw = ta * np.arctan(0.151977 * np.sqrt(hm + 8.313659)) \
             + np.arctan(ta + hm) \
             - np.arctan(hm - 1.676331) \
             + 0.00391838 * hm**1.5 * np.arctan(0.023101 * hm) \
             - 4.686035
        return -0.2442 + 0.55399 * tw + 0.45535 * ta - 0.0022 * tw**2 + 0.00278 * tw * ta + 3.0
    except:
        return np.nan

def calculate_winter_apparent_temp(ta, ws):
    """ê²¨ìš¸ì²  ì²´ê°ì˜¨ë„ ê³„ì‚°"""
    try:
        v = ws * 3.6  # m/s â†’ km/h
        return 13.12 + 0.6215 * ta - 11.37 * v**0.16 + 0.3965 * ta * v**0.16
    except:
        return np.nan

def add_apparent_temp_features(df):
    df['month'] = df['tm'].dt.month
    df['apparent_temp'] = df.apply(lambda row:
        calculate_summer_apparent_temp(row['ta'], row['hm']) if 5 <= row['month'] <= 9
        else calculate_winter_apparent_temp(row['ta'], row['ws']),
        axis=1
    )
    return df



def preprocess_weather_data(df):
    # ë‚ ì§œ ë³€í™˜
    df['tm'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')

    # 1. si: 08~18ì‹œê°€ ì•„ë‹ ë•Œ -99ëŠ” 0ìœ¼ë¡œ
    mask_outside_8_to_18 = (~df['tm'].dt.hour.between(8, 18)) & (df['si'] == -99)
    df.loc[mask_outside_8_to_18, 'si'] = 0

    # 2. wdì—ì„œ 9.9ëŠ” NaNìœ¼ë¡œ
    df['wd'] = df['wd'].replace(9.9, np.nan)

    # 3. -99 ì²˜ë¦¬
    df.replace(-99, np.nan, inplace=True)

    # 4. ë¸Œëœì¹˜ë³„ ì„ í˜•ë³´ê°„ #ê´€ë ¨í•´ì„œ ì—°ì†ëœê±°ëŠ” ì¼ë‹¨ ì•ìª½êº¼ë¡œ ì±„ì›€
    df = df.sort_values(['branch_id', 'tm'])
    df = df.groupby('branch_id').apply(lambda g: g.interpolate(method='linear', limit_direction='both')).reset_index(drop=True)
    df = df.fillna(method='ffill').fillna(method='ffill')
    # ğŸ“Œ íŒŒìƒ ë³€ìˆ˜ ìƒì„±
    df['year'] = df['tm'].dt.year
    df['month'] = df['tm'].dt.month
    df['hour'] = df['tm'].dt.hour
    df['date'] = df['tm'].dt.date
    df['weekday'] = df['tm'].dt.weekday
    df['is_weekend'] = df['weekday'].isin([5,6]).astype(int)

    # ğŸ‡°ğŸ‡· í•œêµ­ ê³µíœ´ì¼
    kr_holidays = holidays.KR()
    df['is_holiday'] = df['tm'].dt.date.apply(lambda x: int(x in kr_holidays))

    # ğŸ•’ ì‹œê°„ ì§€ì—°
    for lag in [1, 2, 3]:
        df[f'ta_lag_{lag}'] = df.groupby('branch_id')['ta'].shift(lag)
        df[f'ta_lag_{lag}'] = df.groupby('branch_id')[f'ta_lag_{lag}'].transform(
        lambda x: x.fillna(method='bfill'))
    # ğŸ”¥ HDD / CDD
    df['HDD18'] = np.maximum(0, 18 - df['ta'])
    df['CDD18'] = np.maximum(0, df['ta'] - 18)
    df['HDD20'] = np.maximum(0, 20 - df['ta'])
    df['CDD20'] = np.maximum(0, df['ta'] - 20)

    #ì§ì ‘ë§Œë“  ì²´ê°ì˜¨ë„
    df = add_apparent_temp_features(df)


    # ì§€ì ë³„ ì˜¨ë„ í¸ì°¨
    branch_mean = df.groupby('branch_id')['ta'].transform('mean')
    df['branch_temp_abs_deviation'] = np.abs(df['ta'] - branch_mean)



    # ì´ë™ í‰ê·  (3ì‹œê°„ ë‹¨ìœ„ ìµœëŒ€ 24ì‹œê°„ = 8ê°œ)
    for n in [3, 6, 9, 12, 15, 18, 21, 24]:
        df[f'ta_3h_avg_{n}'] = df.groupby('branch_id')['ta'].transform(lambda x: x.rolling(n, min_periods=1).mean())

    # ë¶ˆì¾Œì§€ìˆ˜
    df['DCI'] = 0.81 * df['ta'] + 0.01 * df['hm'] * (0.99 * df['ta'] - 14.3) + 46.3

    # í’ì† ëƒ‰ì§€ìˆ˜ (wchi)
    ws_kmh = df['ws'] * 3.6  # m/s -> km/h ë³€í™˜
    df['wchi'] = 13.12 + 0.6215 * df['ta'] - 11.37 * ws_kmh**0.16 + 0.3965 * df['ta'] * ws_kmh**0.16


    # ì‹¤íš¨ì˜¨ë„
    df['e'] = (df['hm'] / 100) * 6.105 * np.exp((17.27 * df['ta']) / (237.7 + df['ta']))
    df['atemphi'] = df['ta'] + 0.33 * df['e'] - 0.70 * df['ws'] - 4.00

    # ì£¼ê¸°ì„± ì¸ì½”ë”©
    df['dayofyear'] = df['tm'].dt.dayofyear
    df['dayofmonth'] = df['tm'].dt.day
    df['weekofyear'] = df['tm'].dt.isocalendar().week.astype(int)

    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)
    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)
    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)

    # í•˜ë£¨ 5êµ¬ê°„
    def time_slot(h): return int(h // 5)
    df['hour_slot_5'] = df['hour'].apply(time_slot)

    def compute_fft_feature(series, n=10):
        fft_vals = np.abs(fft(series.fillna(0)))
        # ì¸ë±ìŠ¤ ì´ë¦„ì„ ëª…í™•íˆ ì§€ì •
        s = pd.Series(fft_vals[:n], index=[f'fft_{i}' for i in range(n)])
        return s

    def compute_fft_feature(series, n=10):
        fft_vals = np.abs(fft(series.fillna(0)))
        s = pd.Series(fft_vals[:n], index=pd.Index([f'fft_{i}' for i in range(n)], name='fft_idx'))
        return s

    fft_cols = ['ta', 'hm', 'ws', 'ta_chi', 'apparent_temp']
    fft_features = []
    branch_ids = df['branch_id'].unique()
    fft_feature_dict = {bid: {} for bid in branch_ids}
    for col in fft_cols:
        if col not in df.columns:
            continue
        for branch_id in branch_ids:
            arr = df.loc[df['branch_id'] == branch_id, col].fillna(0).values
            fft_vals = np.abs(fft(arr))[:10]
            for i, val in enumerate(fft_vals):
                fft_feature_dict[branch_id][f'Nph_{col}_{i}'] = val
                
    # DataFrameìœ¼ë¡œ ë³€í™˜
    fft_features_df = pd.DataFrame.from_dict(fft_feature_dict, orient='index')
    # ì›ë³¸ dfì™€ merge
    df = df.merge(fft_features_df, left_on='branch_id', right_index=True, how='left')
    # ê¸°ì˜¨ ì°¨ë¶„
    df['ta_diff_6h'] = df.groupby('branch_id')['ta'].diff(6).bfill()
    df['ta_diff_12h'] = df.groupby('branch_id')['ta'].diff(12).bfill()
    df['ta_diff_24h'] = df.groupby('branch_id')['ta'].diff(24).bfill()

    # ì¼êµì°¨
    df['day_ta_max'] = df.groupby(['branch_id', df['tm'].dt.date])['ta'].transform('max')
    df['day_ta_min'] = df.groupby(['branch_id', df['tm'].dt.date])['ta'].transform('min')
    df['daily_range'] = df['day_ta_max'] - df['day_ta_min']

    # ì¼êµì°¨ ë³€í™”ëŸ‰
    df['daily_range_shift'] = df.groupby('branch_id')['daily_range'].shift(1).bfill()

    # í”¼í¬íƒ€ì„1
    df['peak_time1'] = 0
    df.loc[(df['hour'] >= 0) & (df['hour'] <= 6), 'peak_time1'] = 1
    df.loc[(df['hour'] > 6) & (df['hour'] <= 11), 'peak_time1'] = 2
    df.loc[(df['hour'] > 11) & (df['hour'] <= 18), 'peak_time1'] = 3
    df.loc[(df['hour'] > 18) & (df['hour'] <= 23), 'peak_time1'] = 4

    # í”¼í¬íƒ€ì„2
    df['peak_time2'] = 0
    df.loc[(df['hour'] >= 2) & (df['hour'] <= 10), 'peak_time2'] = 1


    # heating season
    df['heating_season'] = df['month'].isin([10,11,12,1, 2, 3,4]).astype(int)

    # ì˜¨ë„ ë²”ì£¼í™”
    df['temp_category20'] = pd.cut(df['ta'], bins=[-np.inf, 20, np.inf], labels=['low', 'high'])
    df['temp_category18'] = pd.cut(df['ta'], bins=[-np.inf, 18, np.inf], labels=['low', 'high'])
    df['temp_category16'] = pd.cut(df['ta'], bins=[-np.inf, 16, np.inf], labels=['low', 'high'])

    # ì˜¤ì „/ì˜¤í›„
    df['afternoon'] = (df['hour'] >= 12).astype(int)

    # ê³„ì ˆ
    def get_season(month):
        return {
            12: 'winter', 1: 'winter', 2: 'winter',
            3: 'spring', 4: 'spring', 5: 'spring',
            6: 'summer', 7: 'summer', 8: 'summer',
            9: 'fall', 10: 'fall', 11: 'fall'
        }.get(month, 'unknown')
    df['season'] = df['month'].apply(get_season)

    # í•œíŒŒ ì£¼ì˜ë³´/ê²½ë³´
    df['cold_watch'] = (df['ta'] <= -12).astype(int)  # ì£¼ì˜ë³´
    df['cold_warning'] = (df['ta'] <= -15).astype(int)  # ê²½ë³´

    # í’ì† ê³ ë ¤ ì²´ê°ì˜¨ë„ (wind chill)
    df['wind_chill'] = 13.12 + 0.6215 * df['ta'] - 11.37 * df['ws']**0.16 + 0.3965 * df['ta'] * df['ws']**0.16

    # ë³€í™˜ ëŒ€ìƒ ë³€ìˆ˜
    col = 'ta'

    df['ta_boxcox'] = np.nan
    df['ta_boxcox_lambda'] = np.nan
    df['ta_boxcox_shift'] = np.nan  # shift ê°’ë„ ì €ì¥

    for branch, group in df.groupby('branch_id'):
        col = 'ta'
        min_val = group[col].min()
        if min_val <= 0:
            shift = abs(min_val) + 1e-4
        else:
            shift = 0
        shifted = group[col] + shift
        shifted = shifted.dropna()
        if shifted.nunique() > 1 and len(shifted) >= 2:
            transformed, fitted_lambda = boxcox(shifted)
            df.loc[shifted.index, 'ta_boxcox'] = transformed
            df.loc[shifted.index, 'ta_boxcox_lambda'] = fitted_lambda
            df.loc[shifted.index, 'ta_boxcox_shift'] = shift
        else:
            df.loc[group.index, 'ta_boxcox'] = np.nan
            df.loc[group.index, 'ta_boxcox_lambda'] = np.nan
            df.loc[group.index, 'ta_boxcox_shift'] = shift

    
    df = df.drop(columns=['tm', 'year', 'month','hour','date'])



    return df
#ìƒí˜¸ì‘ìš© ì²˜ë¦¬ëª»í•¨
#êµ°ì§‘í™”ëœ ì „ì²˜ë¦¬ ëª»í•¨


#ì •ê·œí™” ì¼ë‹¨ min max +ì›í•«ì¸ì½”ë”©
def scale_encode(df):
    cat_cols = [
        'branch_id', 'peak_time1', 'peak_time2', 'heating_season',
        'temp_category16', 'temp_category18', 'temp_category20',
        'afternoon', 'season'
    ]

    # ë²”ì£¼í˜• ë³€ìˆ˜ categoryí™”
    for col in cat_cols:
        if col in df.columns:
            df[col] = df[col].astype('category')

    # ì›-í•« ì¸ì½”ë”©
    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

    # ì—°ì†í˜• ë³€ìˆ˜ë§Œ ì¶”ì¶œ (íƒ€ê²Ÿ, ë‚ ì§œ ë“± ì œì™¸)
    exclude_cols = ['heat_demand', 'branch_id', 'peak_time1', 'peak_time2', 'heating_season',
        'temp_category16', 'temp_category18', 'temp_category20','afternoon', 'season']
    num_cols = [col for col in df.columns
                if (df[col].dtype in [np.float64, np.int64]) and (col not in exclude_cols)]

    # MinMaxScaler ì ìš©
    scaler = MinMaxScaler()
    df[num_cols] = scaler.fit_transform(df[num_cols])


    return df



df_train = preprocess_weather_data(df_train)
df_test = preprocess_weather_data(df_test)
df_train = scale_encode(df_train)
df_test = scale_encode(df_test)