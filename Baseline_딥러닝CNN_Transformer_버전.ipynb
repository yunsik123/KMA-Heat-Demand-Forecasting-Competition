{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZRjHM_q-q3",
        "outputId": "a935ab7c-2c16-4b6e-8ed9-1f8fa22ed39e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LCqUVPrPrVUN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2756hKwxasB",
        "outputId": "2234f827-dada-41c3-c1be-9f0520284c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0\n",
            "0 0\n"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리\n",
        "# ---------------------\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/train_heat.csv', encoding='CP949')\n",
        "df = df.replace(-99, np.nan)\n",
        "df = df.drop(columns='Unnamed: 0')\n",
        "\n",
        "df['train_heat.tm'] = pd.to_datetime(df['train_heat.tm'].astype(str), format='%Y%m%d%H')\n",
        "df = df.sort_values('train_heat.tm').set_index('train_heat.tm')\n",
        "\n",
        "hour = df.index.hour\n",
        "df.loc[~((hour >= 8) & (hour <= 18)), 'train_heat.si'] = 0\n",
        "\n",
        "# 선형보간 함수 정의\n",
        "def linear_impute(series):\n",
        "    return series.interpolate(method='linear')\n",
        "\n",
        "# 결측치가 있는 컬럼 자동 탐색 및 선형보간 적용\n",
        "cols_to_impute = df.columns[df.isnull().any()].tolist()\n",
        "for col in cols_to_impute:\n",
        "    df[col] = linear_impute(df[col])\n",
        "\n",
        "# 파생 변수 생성\n",
        "df['year'] = df.index.year\n",
        "df['month'] = df.index.month\n",
        "df['day'] = df.index.day\n",
        "df['hour'] = df.index.hour\n",
        "df['weekday'] = df.index.weekday\n",
        "\n",
        "df['heating_season'] = df['month'].apply(lambda x: 1 if x in [10, 11, 12, 1, 2, 3, 4] else 0)\n",
        "df['temp_category'] = df['train_heat.ta'].apply(lambda x: 1 if x >= 20 else 0)\n",
        "\n",
        "def peak_time_category(hour):\n",
        "    if 0 <= hour <= 6:\n",
        "        return 0\n",
        "    elif 6 < hour <= 12:\n",
        "        return 1\n",
        "    elif 12 < hour <= 18:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "df['peak_time'] = df['hour'].apply(peak_time_category)\n",
        "\n",
        "for lag in [1, 2, 3]:\n",
        "    lag_col = f'ta_lag_{lag}'\n",
        "    df[lag_col] = df['train_heat.ta'].shift(lag)\n",
        "    df[lag_col] = df[lag_col].interpolate(method='linear', limit_direction='both')  # 또는 .ewm().mean()\n",
        "\n",
        "base_temp = 18.0\n",
        "df['HDD'] = (base_temp - df['train_heat.ta']).clip(lower=0)\n",
        "df['CDD'] = (df['train_heat.ta'] - base_temp).clip(lower=0)\n",
        "df['branch_temp_abs_deviation'] = (df['train_heat.ta'] - df.groupby('train_heat.branch_id')['train_heat.ta'].transform('mean')).abs()\n",
        "\n",
        "df = df.query('`train_heat.branch_id` in [\"A\", \"B\", \"D\"]')\n",
        "\n",
        "# 타겟 변수\n",
        "target = 'train_heat.heat_demand'\n",
        "\n",
        "# 피처 선택\n",
        "features = [\n",
        "    \"train_heat.ta\", \"train_heat.wd\", \"train_heat.ws\", \"train_heat.rn_day\", \"train_heat.rn_hr1\",\n",
        "    \"train_heat.hm\", \"train_heat.si\", \"train_heat.ta_chi\",\n",
        "    \"ta_lag_1\", \"ta_lag_2\", \"ta_lag_3\", \"HDD\", \"CDD\", \"branch_temp_abs_deviation\"\n",
        "]\n",
        "\n",
        "# 범주형 인코딩\n",
        "df = pd.get_dummies(df, columns=[\"month\", \"weekday\", \"heating_season\", \"temp_category\", \"peak_time\"])\n",
        "\n",
        "# 연도별 분리\n",
        "df_train = df[df['year'] == 2021]\n",
        "df_test = df[df['year'] == 2022]\n",
        "\n",
        "X_train = df_train[features + [col for col in df.columns if col.startswith(('month_', 'weekday_', 'heating_season_', 'temp_category_', 'peak_time_'))]]\n",
        "y_train = df_train[target]\n",
        "X_test = df_test[X_train.columns]\n",
        "y_test = df_test[target]\n",
        "\n",
        "# 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#결측치확인\n",
        "print(np.isnan(X_train).sum(), np.isinf(X_train).sum())\n",
        "print(np.isnan(y_train).sum(), np.isinf(y_train).sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMcdShLUrWPh",
        "outputId": "6129b7df-86b1-428e-b7f6-58936fdb9397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 7335.8108\n",
            "Epoch 2/20, Loss: 5524.2522\n",
            "Epoch 3/20, Loss: 5396.4467\n",
            "Epoch 4/20, Loss: 5354.6651\n",
            "Epoch 5/20, Loss: 5301.1365\n",
            "Epoch 6/20, Loss: 5256.9323\n",
            "Epoch 7/20, Loss: 5204.3312\n",
            "Epoch 8/20, Loss: 5191.0447\n",
            "Epoch 9/20, Loss: 5137.0592\n",
            "Epoch 10/20, Loss: 5140.5681\n",
            "Epoch 11/20, Loss: 5151.2264\n",
            "Epoch 12/20, Loss: 5107.1200\n",
            "Epoch 13/20, Loss: 5112.4250\n",
            "Epoch 14/20, Loss: 5088.7737\n",
            "Epoch 15/20, Loss: 5083.4311\n",
            "Epoch 16/20, Loss: 5094.9944\n",
            "Epoch 17/20, Loss: 5068.3824\n",
            "Epoch 18/20, Loss: 5052.5831\n",
            "Epoch 19/20, Loss: 5071.7730\n",
            "Epoch 20/20, Loss: 5028.6116\n",
            "RMSE: 77.84707439709922\n"
          ]
        }
      ],
      "source": [
        "# Dataset 정의\n",
        "# ---------------------\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y, window_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X) - self.window_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_seq = self.X[idx:idx+self.window_size]\n",
        "        y_target = self.y[idx + self.window_size]\n",
        "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_target, dtype=torch.float32)\n",
        "\n",
        "# ---------------------\n",
        "# CNN + Transformer 모델\n",
        "# ---------------------\n",
        "class CNNTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=128, nhead=8, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Conv1d(in_channels=input_dim, out_channels=d_model, kernel_size=3, padding=1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(d_model * window_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.permute(0, 2, 1)        # [B, F, T]\n",
        "      x = self.cnn(x)               # [B, D, T]\n",
        "      x = x.permute(0, 2, 1)        # [B, T, D]\n",
        "      x = self.transformer(x)       # [B, T, D]\n",
        "      x = x.permute(0, 2, 1)        # [B, D, T]  ← 추가!\n",
        "      return self.head(x)           # → [B, 1]\n",
        "\n",
        "# ---------------------\n",
        "# 학습 파라미터 및 실행\n",
        "# ---------------------\n",
        "window_size = 48  # 24시간 단위로 학습\n",
        "train_dataset = TimeSeriesDataset(X_train, y_train.values, window_size)\n",
        "test_dataset = TimeSeriesDataset(X_test, y_test.values, window_size)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNTransformer(input_dim=X_train.shape[1]).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# ---------------------\n",
        "# 학습 루프\n",
        "# ---------------------\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x_batch)\n",
        "        loss = criterion(preds, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# ---------------------\n",
        "# 평가\n",
        "# ---------------------\n",
        "model.eval()\n",
        "preds, trues = [], []\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        pred = model(x_batch).cpu().squeeze()\n",
        "        preds.append(pred)\n",
        "        trues.append(y_batch)\n",
        "\n",
        "y_pred = torch.cat(preds).numpy()\n",
        "y_true = torch.cat(trues).numpy()\n",
        "\n",
        "print(\"RMSE:\", mean_squared_error(y_true, y_pred) ** 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG__D4Bk5OUm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE09y2Cl5OR_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI-6O-zv5OPf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsMUL3AD5OMq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqYPzjNG5OHv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQESUAfKrWIb",
        "outputId": "e7263c1c-08b0-4753-ef32-c3bbfa41045c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 16449.7594\n",
            "Epoch 2/20, Loss: 5619.9570\n",
            "Epoch 3/20, Loss: 5411.8238\n",
            "Epoch 4/20, Loss: 5358.6079\n",
            "Epoch 5/20, Loss: 5318.5205\n",
            "Epoch 6/20, Loss: 5254.1346\n",
            "Epoch 7/20, Loss: 5215.4381\n",
            "Epoch 8/20, Loss: 5202.4277\n",
            "Epoch 9/20, Loss: 5213.3516\n",
            "Epoch 10/20, Loss: 5182.5410\n",
            "Epoch 11/20, Loss: 5168.2464\n",
            "Epoch 12/20, Loss: 5107.3182\n",
            "Epoch 13/20, Loss: 5112.1123\n",
            "Epoch 14/20, Loss: 5123.1483\n",
            "Epoch 15/20, Loss: 5097.3559\n",
            "Epoch 16/20, Loss: 5083.6693\n",
            "Epoch 17/20, Loss: 5071.6963\n",
            "Epoch 18/20, Loss: 5102.3098\n",
            "Epoch 19/20, Loss: 5041.2941\n",
            "Epoch 20/20, Loss: 5048.3259\n",
            "RMSE: 77.89128165470446\n"
          ]
        }
      ],
      "source": [
        "# Dataset 정의\n",
        "# ---------------------\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y, window_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X) - self.window_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_seq = self.X[idx:idx+self.window_size]\n",
        "        y_target = self.y[idx + self.window_size]\n",
        "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_target, dtype=torch.float32)\n",
        "\n",
        "# ---------------------\n",
        "# CNN + Transformer 모델\n",
        "# ---------------------\n",
        "class CNNTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=128, nhead=8, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Conv1d(in_channels=input_dim, out_channels=d_model, kernel_size=3, padding=1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),  # [B, D, T] → [B, D, 1]\n",
        "            nn.Flatten(),             # [B, D, 1] → [B, D]\n",
        "            nn.Linear(d_model, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # [B, F, T] → [B, T, F] → CNN expects [B, F, T]\n",
        "        x = self.cnn(x)         # [B, D, T]\n",
        "        x = x.permute(0, 2, 1)  # [B, D, T] → [B, T, D] (for transformer)\n",
        "        x = self.transformer(x) # [B, T, D]\n",
        "        x = x.permute(0, 2, 1)  # [B, T, D] → [B, D, T] (for pooling)\n",
        "        x = self.head(x)        # [B, D, T] → [B, D, 1] → [B, D] → [B, 1]\n",
        "        return x\n",
        "\n",
        "# ---------------------\n",
        "# 학습 파라미터 및 실행\n",
        "# ---------------------\n",
        "window_size = 48  # 24시간 단위로 학습\n",
        "train_dataset = TimeSeriesDataset(X_train, y_train.values, window_size)\n",
        "test_dataset = TimeSeriesDataset(X_test, y_test.values, window_size)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNTransformer(input_dim=X_train.shape[1]).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# ---------------------\n",
        "# 학습 루프\n",
        "# ---------------------\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x_batch)\n",
        "        loss = criterion(preds, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# ---------------------\n",
        "# 평가\n",
        "# ---------------------\n",
        "model.eval()\n",
        "preds, trues = [], []\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        pred = model(x_batch).cpu().squeeze()\n",
        "        preds.append(pred)\n",
        "        trues.append(y_batch)\n",
        "\n",
        "y_pred = torch.cat(preds).numpy()\n",
        "y_true = torch.cat(trues).numpy()\n",
        "\n",
        "print(\"RMSE:\", mean_squared_error(y_true, y_pred) ** 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keg3dS6nrWF6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0lw_q7Auag2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
